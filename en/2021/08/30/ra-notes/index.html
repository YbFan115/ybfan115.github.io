<a name=top></a><!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>RA Notes - Hugo-HT</title><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/fonts.css><link href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css rel=stylesheet><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/r.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/bash.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/python.min.js></script><script src=https://cdn.jsdelivr.net/npm/vega@5.17.0></script><script src=https://cdn.jsdelivr.net/npm/vega-lite@4.17.0></script><script src=https://cdn.jsdelivr.net/npm/vega-embed@6.12.2></script><script>hljs.initHighlightingOnLoad();</script><link rel=icon href=https://example.com/media/hugo-logo.png></head><body><div class=wrapper><header class=header><nav class=nav><a href=/ class=nav-logo><img src=/media/hugo-logo.png width=50 height=50 alt=Hugo-ht></a><ul class=nav-links><li><a href=/>Home</a></li><li><a href=/en/about/>About</a></li><li><a href=/en/posts/>Posts</a></li><li><a href=/cn/posts/>中文</a></li></ul></nav></header><main class=content role=main><div style=text-align:center><h1>RA Notes</h1><p>/ 2021-08-30</p><hr></div><span class=article-toolbar><a href=https://github.com/USERNAME/REPONAME/edit/master/content/en/posts/RA-notes.md style=font-size:24px;color:#000 target=_blank><i class="fa fa-edit" aria-hidden=true title="Suggest an edit of this page"></i></a></span><div class="body-text list-text"><p><strong>Notes</strong>: This post is written to keep the ideas alive and document what I learn from the research work with <a href=https://teblunthuis.cc target=_blank rel="noreferrer noopener">Nate</a>
. Since Aug. 2021, I began to contribute to the project of Nate which is intended to find the connections between two online communities - <a href=https://www.fandom.com/explore target=_blank rel="noreferrer noopener">Fandom wiki</a>
(which was previously known as Wikia) and <a href=www.reddit.com>Reddit</a>
. I make a role in the dataset construction.</p><ul><li><p><strong>Wikidata and SPARQL language</strong>: Wikidata is an open source knowledge graph that has structured data about relationships between different entities. Here is an example: <a href=https://www.wikidata.org/wiki/Q673 target=_blank rel="noreferrer noopener">One Piece</a>
. Wikidata provides a query service which can run by SPARQL language, to find the qualified entities and properties in the dataset. I have learned the rules for SPARQL, and pulled the entities that have both a fandom wiki and a subreddit ID.</p></li><li><p><strong>Precision and recall</strong>: How good the mapping in Wikidata is to be checked. Precision and recall rate can be used to examine it.</p></li><li><p><strong>Linux</strong>: To be more efficient to collaborate, I set the Linux and began to join the git of <a href=https://wiki.communitydata.science/Main_Page target=_blank rel="noreferrer noopener">Community Data Science Collective</a>
, which is a research group focused on online communities.</p><ul><li>use <code>explorer.exe .</code> to find the Linux files in Windows</li><li>if <code>sudo apt install ...</code> fails, it can probably be solved by <code>sudo apt install -y ... --fix-missing</code>(see in <a href="https://help.aliyun.com/knowledge_detail/41205.html?spm=a2c6h.13066369.0.0.21837b3ejhCgyA" target=_blank rel="noreferrer noopener">Help Docs</a>
)</li><li>to find the ip for linux, use <code>ifconfig -a</code></li><li>to open xrdp, use <code>sudo service xrdp restart</code></li></ul></li><li><p><strong>Wikidata</strong>: According to the query outcome in Wikidata, it seems like dataset in Wikidata does not have a good coverage for the match between a fandom wiki and a subreddit, but include almost no error due to the properties for Wikipedia. We are going to deal with more data to get back at the dataset in Wikidata.</p></li><li><p><strong>Machine Learning Classification</strong>: To find out whether a subreddit and a fandom wiki is really similar or the mapping between them is correct, there can be some ideas from <a href=https://machinelearningmastery.com/types-of-classification-in-machine-learning/ target=_blank rel="noreferrer noopener">machine learning classification</a>
.</p></li><li><p><strong>Machine Learning for Social Sciences</strong>: Machine learning models used in social sciences has triggered a heated discussion: whether it is &ldquo;garbage in, garbage out&rdquo; (<a href=https://doi.org/10.1145/3351095.3372862 target=_blank rel="noreferrer noopener">Geiger et al., 2019</a>
) or &ldquo;theory in, theory out&rdquo; (<a href=https://doi.org/10.3389/fdata.2020.00018 target=_blank rel="noreferrer noopener">Radford & Joseph, 2020</a>
)?</p></li><li><p><strong>Rules for prediction</strong>: Simpler than real ML classifier, if we give a set of rules to predict the correctnesss of mappings it would also make sense. An example rule Nate gave is:</p><pre><code>The wiki is the top linked wiki from the subreddit AND
(The subreddit and wiki are linked in wikidata OR
    The subreddit and wiki names are similar OR
    The subreddit-link zscore for the wiki is large
    )
</code></pre><pre><code></code></pre></li><li><p><strong>Validation Set</strong></p></li><li><p><strong>More text features</strong>: We expanded the rules to check the text match ratio besides edit distance by using <a href=https://towardsdatascience.com/sequencematcher-in-python-6b1e6f3915fc target=_blank rel="noreferrer noopener">SequenceMatcher</a>
, to make a more complicated and accurate prediction. This is quite connected with <a href=https://en.wikipedia.org/wiki/Natural_language_processing target=_blank rel="noreferrer noopener">Natural Language Processing</a>
.</p></li><li><p>I have labeled 200 more cases and done a logistical regression model for testing if the above rules of prediction work well for a larger set.</p></li><li><p><strong>MapReduce</strong>: MapReduce is a programming model. It is composed of a <strong>map</strong> procedure, which conducts filtering and sorting, and a <strong>reduce</strong> method, which conducts a summary operation.</p></li><li><p>Simulation: Reality is recursive. The macro outcome can be often surprising even if we have known the micro behavior well. Simulation methods, especially <strong>agent-based models</strong>, can be used to study the emergence in the complex systems, such as how individual behavior bias can accumulate to the group size difference (<a href=https://arxiv.org/abs/2006.03119v1 target=_blank rel="noreferrer noopener">Foote et al., 2020</a>
). Simulation can be a promising field and method to address the micro-macro link in social scientific research.</p></li><li><p>Hyak: High performance computer cluster at UW. It can be used to conduct large amount of computing.</p></li></ul><p style=color:#777>Last modified on 2021-08-30</p></div><a href=#top><i class="fa fa-chevron-up" style=font-size:30px;color:#000></i></a></main><footer class=footer><script type=text/javascript src=/js/math-code.js></script><script async src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script><script type=text/javascript src=/js/center-img.js></script><ul class=footer-links><li><a href=/en/posts/index.xml type=application/rss+xml title="RSS feed">Subscribe</a></li><li><a href=http://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank>License
<i class="fa fa-cc" aria-hidden=true title="Attribution-NonCommercial-ShareAlike 4.0 International"></i></a></li></ul><div class=copyright-text>©
Your Name
2020-2021</div></footer>